# Spark Log4j2 Configuration for Migration Tool
# Set everything to be logged to the console with reduced verbosity

# Root logger set to WARN to reduce noise
rootLogger.level = warn
rootLogger.appenderRef.stdout.ref = console

# Console appender configuration
appender.console.type = Console
appender.console.name = console
appender.console.target = SYSTEM_ERR
appender.console.layout.type = PatternLayout
appender.console.layout.pattern = %d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n%ex

# Set Spark-specific loggers to reduce verbosity
logger.spark.name = org.apache.spark
logger.spark.level = warn

logger.sparkconf.name = org.apache.spark.SparkConf
logger.sparkconf.level = error

logger.sparkutils.name = org.apache.spark.util.Utils
logger.sparkutils.level = error

logger.sparksql.name = org.apache.spark.sql
logger.sparksql.level = warn

# Hadoop loggers
logger.hadoop.name = org.apache.hadoop
logger.hadoop.level = error

# Set the default spark-shell/spark-sql log level to WARN
logger.repl.name = org.apache.spark.repl.Main
logger.repl.level = warn

logger.thriftserver.name = org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver
logger.thriftserver.level = warn

# Settings to quiet third party logs that are too verbose
logger.jetty1.name = org.sparkproject.jetty
logger.jetty1.level = error
logger.jetty2.name = org.sparkproject.jetty.util.component.AbstractLifeCycle
logger.jetty2.level = error
logger.replexprTyper.name = org.apache.spark.repl.SparkIMain$exprTyper
logger.replexprTyper.level = warn
logger.replSparkILoopInterpreter.name = org.apache.spark.repl.SparkILoop$SparkILoopInterpreter
logger.replSparkILoopInterpreter.level = warn
logger.parquet1.name = org.apache.parquet
logger.parquet1.level = error
logger.parquet2.name = parquet
logger.parquet2.level = error

# Hive-related loggers
logger.RetryingHMSHandler.name = org.apache.hadoop.hive.metastore.RetryingHMSHandler
logger.RetryingHMSHandler.level = fatal
logger.FunctionRegistry.name = org.apache.hadoop.hive.ql.exec.FunctionRegistry
logger.FunctionRegistry.level = error

# Suppress shutdown hook errors
logger.shutdownhook.name = org.apache.spark.util.ShutdownHookManager
logger.shutdownhook.level = error

# Filter out TTransportException warnings (commented out due to issues)
# appender.console.filter.1.type = RegexFilter
# appender.console.filter.1.regex = .*Thrift error occurred during processing of message.*
# appender.console.filter.1.onMatch = deny
# appender.console.filter.1.onMismatch = neutral

# Filter out temp directory warnings (commented out due to issues)
# appender.console.filter.2.type = RegexFilter
# appender.console.filter.2.regex = .*The configured local directories are not expected to be URIs.*
# appender.console.filter.2.onMatch = deny
# appender.console.filter.2.onMismatch = neutral
